{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":61247,"databundleVersionId":8550470,"sourceType":"competition"}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Install libraries","metadata":{}},{"cell_type":"code","source":"!mkdir /tmp/submission","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-30T11:27:37.674845Z","iopub.execute_input":"2024-07-30T11:27:37.675268Z","iopub.status.idle":"2024-07-30T11:27:38.760625Z","shell.execute_reply.started":"2024-07-30T11:27:37.675218Z","shell.execute_reply":"2024-07-30T11:27:38.759501Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"mkdir: cannot create directory '/tmp/submission': File exists\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\nimport os,sys\nos.system(\"pip install -U -t /tmp/submission/lib accelerate bitsandbytes\")\nos.system(\"pip cache purge\")\nsys.path.insert(0, \"/tmp/submission/lib\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\nimport torch\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit = True,\n    bnb_4bit_quanty_type = \"fp4\", \n    bnb_4bit_compute_dtype=torch.float16,\n    bnb_4bit_use_double_quanty = True,\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\"abacusai/Llama-3-Smaug-8B\", \n                                              quantization_config = bnb_config,\n                                              torch_dtype = torch.float16,\n                                              device_map = \"auto\",\n                                              trust_remote_code = True)\n\ntokenizer = AutoTokenizer.from_pretrained(\"abacusai/Llama-3-Smaug-8B\")","metadata":{"execution":{"iopub.status.busy":"2024-07-30T11:46:58.574340Z","iopub.execute_input":"2024-07-30T11:46:58.574779Z","iopub.status.idle":"2024-07-30T11:49:30.213347Z","shell.execute_reply.started":"2024-07-30T11:46:58.574747Z","shell.execute_reply":"2024-07-30T11:49:30.212479Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"Unused kwargs: ['bnb_4bit_quanty_type', 'bnb_4bit_use_double_quanty']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/649 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ff8948a6773476db8c85dd15c30b6e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e882a8d5627442c937623c5ac6741c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08fada287b3a41e0b7851b5cf1c19666"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c33da85827d04fc6bb43a717fbd08144"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10b4f8d34f04494eb635231201ef5964"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2cda8a396e1428290f34922af2d523c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4deecfaffa064a018e753d3bd46a2b40"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66e34b74687d4551aa6798531f6a8422"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/121 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7301c8dd277e4ea59afe4cf40e982b48"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/51.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"056d94cc3be94654b53e3c5ddef1a6f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"832cac4f56ed4c59a4ed3e7b29608b81"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/449 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce06a707274341888cb2a4dd0ef34f4e"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save_pretrained(\"/tmp/submission/weights\")\ntokenizer.save_pretrained(\"/tmp/submission/weights\")","metadata":{"execution":{"iopub.status.busy":"2024-07-30T11:54:38.713384Z","iopub.execute_input":"2024-07-30T11:54:38.713917Z","iopub.status.idle":"2024-07-30T11:54:56.832377Z","shell.execute_reply.started":"2024-07-30T11:54:38.713887Z","shell.execute_reply":"2024-07-30T11:54:56.831389Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"('/tmp/submission/weights/tokenizer_config.json',\n '/tmp/submission/weights/special_tokens_map.json',\n '/tmp/submission/weights/tokenizer.json')"},"metadata":{}}]},{"cell_type":"markdown","source":"## Experimenting with Llama","metadata":{}},{"cell_type":"code","source":"pad_token_id = tokenizer.pad_token_id\nif pad_token_id is None:\n    pad_token_id = tokenizer.eos_token_id","metadata":{"execution":{"iopub.status.busy":"2024-07-30T11:57:19.213410Z","iopub.execute_input":"2024-07-30T11:57:19.214126Z","iopub.status.idle":"2024-07-30T11:57:19.218899Z","shell.execute_reply.started":"2024-07-30T11:57:19.214090Z","shell.execute_reply":"2024-07-30T11:57:19.217700Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"prompt = \"What is the capital of Hungary?\"\n\nmessages = [\n    {\"role\": \"system\", \"content\": \"You are a friendly assistant\"},\n    {\"role\": \"user\", \"content\": prompt}\n]\n\ntext = tokenizer.apply_chat_template(\n    messages,\n    tokenize=False,\n    add_generation_prompt=True\n)\nmodel_inputs = tokenizer([text], return_tensors=\"pt\").to('cuda')\n\ngenerated_ids = model.generate(\n    model_inputs.input_ids,\n    attention_mask = model_inputs.attention_mask,\n    pad_token_id=pad_token_id,\n    max_new_tokens=20\n)\n\ngenerated_ids = [\n    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n]\n\nresponse = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n\nprint(response)","metadata":{"execution":{"iopub.status.busy":"2024-07-30T12:35:24.645014Z","iopub.execute_input":"2024-07-30T12:35:24.645761Z","iopub.status.idle":"2024-07-30T12:35:26.265682Z","shell.execute_reply.started":"2024-07-30T12:35:24.645727Z","shell.execute_reply":"2024-07-30T12:35:26.264680Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"The capital of Hungary is Budapest.assistant\n\nThe capital of Hungary is Budapest.\n","output_type":"stream"}]},{"cell_type":"code","source":"#%%writefile /tmp/submission/main.py\n\n################\n# DETERMINE IF SUBMIT OR COMMIT\nimport os\nKAGGLE_AGENT_PATH = \"/kaggle_simulations/agent/\"\nVERBOSE = False\nif not os.path.exists(KAGGLE_AGENT_PATH + \"weights\"):\n    KAGGLE_AGENT_PATH = \"/tmp/submission/\"\n    VERBOSE = True\n\n#################\n# LOAD MODEL INTO MEMORY\nimport sys, torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\nsys.path.insert(0, f\"{KAGGLE_AGENT_PATH}lib\")\nmodel = AutoModelForCausalLM.from_pretrained(\n    f\"{KAGGLE_AGENT_PATH}weights/\",\n    torch_dtype = torch.float16,\n    device_map = \"auto\",\n    trust_remote_code = True,\n)\ntokenizer = AutoTokenizer.from_pretrained(f\"{KAGGLE_AGENT_PATH}weights/\")\n\n##############\n# BINARY SEARCH AS QUESTIONER\nimport pandas as pd, numpy as np\nkeywords = pd.read_csv(KAGGLE_AGENT_PATH + \"keywords_v2.csv\")\nkeywords['guess'] = 0\n\ncategories = [\"city\",\"country\",\"landmark\"]\n#np.random.shuffle(categories)\ncategory_yes = []\ncategory_no = []\ncat_guess = 0\n\ncontinents = [\"Europe\",\"Asia\",\"North America\",\"Africa\",\"South America\",\"Australia\"]\n#np.random.shuffle(continents)\ncontinent_yes = []\ncontinent_no = []\ncon_guess = 0\n\nfirst_letters = []\nfirst_letter_yes = []\nfirst_letter_no = []\nlet_guess = 0\nextra_guess = \"\"\n\n###############\n# LLM MODEL AS ANSWERER\ndef get_yes_no(question,keyword):\n    global keywords, VERBOSE\n    \n    if keyword in keywords.keyword.values:\n        row = keywords.loc[keywords.keyword==keyword].iloc[0]\n        category = row.category #\"landmark\"\n        continent = row.continent #\"North America\"\n        negate = {\n            \"city\":\"Is is not a country. It is not a landmark.\",\n            \"country\":\"Is is not a city. It is not a landmark.\",\n            \"landmark\":\"Is is not a city. It is not a country.\",\n        }\n        prompt = f\"We are playing 20 questions. The keyword is {keyword}. It is a {category}. {negate[category]} This word has first letter {keyword[0]}. This {category} is located in {continent}. {question}\"\n    else:\n        prompt = f\"We are playing 20 questions. The keyword is {keyword}. It is a thing. Is is not a city. It is not a country. It is not a landmark. This word has first letter {keyword[0]}. {question}\"\n    \n    messages = [\n        {\"role\": \"system\", \"content\": \"Answer yes or no to the following question and nothing else.\"},\n        {\"role\": \"user\", \"content\": prompt}\n    ]\n    text = tokenizer.apply_chat_template(\n        messages,\n        tokenize=False,\n        add_generation_prompt=True\n    )\n    model_inputs = tokenizer([text], return_tensors=\"pt\").to('cuda')\n    \n    pad_token_id = tokenizer.pad_token_id\n    if pad_token_id is None:\n        pad_token_id = tokenizer.eos_token_id\n        \n    generated_ids = model.generate(\n        model_inputs.input_ids,\n        attention_mask = model_inputs.attention_mask,\n        pad_token_id = pad_token_id,\n        max_new_tokens=1\n    )\n    generated_ids = [\n        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n    ]\n\n    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n    if not \"yes\" in response.lower(): response = \"no\"\n    else: response = \"yes\"\n        \n    if VERBOSE:\n        print(f\"### {prompt}\")\n        \n    return response\n\n############\n# MAIN AGENT FUNCTION\ndef agent_fn(obs, cfg):\n    global keywords, extra_guess, VERBOSE\n    global categories, category_yes, category_no, cat_guess\n    global continents, continent_yes, continent_no, con_guess\n    global first_letters, first_letter_yes, first_letter_no, let_guess\n        \n    # GENERATE RESPONSE\n    if obs.turnType == \"ask\":\n        \n        if (cat_guess<3)&(len(category_yes)==0):\n            response = f\"Is the keyword the name of a {categories[cat_guess]}?\"\n            cat_guess += 1\n        elif (con_guess<6)&(len(continent_yes)==0):\n            category = \"place\"\n            if len( category_yes )==1: \n                category = category_yes[0]\n            response = f\"Is the {category} located in {continents[con_guess]}?\"\n            con_guess += 1\n        else:\n            IDX = keywords.category.isin( category_yes )\n            IDX = IDX & (keywords.continent.isin( continent_yes ))\n            first_letters = list(keywords.loc[IDX,\"first_letter\"].value_counts().index.values)\n            if let_guess < len(first_letters):\n                response = f\"Does the keyword begin with the letter {first_letters[let_guess]}?\"\n            else:\n                IDX = keywords.guess == 0\n                if len(category_yes)>0: IDX = IDX & (keywords.category.isin(category_yes))\n                if len(category_no)>0: IDX = IDX & (~keywords.category.isin(category_no))\n                if len(continent_yes)>0: IDX = IDX & (keywords.continent.isin(continent_yes))\n                if len(continent_no)>0: IDX = IDX & (~keywords.continent.isin(continent_no))\n                if len(first_letter_yes)>0: IDX = IDX & (keywords.first_letter.isin(first_letter_yes))\n                if len(first_letter_no)>0: IDX = IDX & (~keywords.first_letter.isin(first_letter_no))\n                try:\n                    guess = keywords.loc[IDX].sample(1).index.values[0]\n                    keywords.loc[guess,'guess'] = 1\n                    response = keywords.loc[guess,\"keyword\"]\n                except:\n                    response = np.random.choice( keywords.keyword.values )\n                extra_guess = response\n                response = f\"Is it {response}?\"\n            let_guess += 1\n            \n    elif obs.turnType == \"guess\":\n        \n        category_yes = []\n        category_no = []\n        for k in range(cat_guess):\n            if obs.answers[k]==\"yes\":\n                category_yes.append( categories[k] )\n            else:\n                category_no.append( categories[k] )\n        if (cat_guess==3)&(len(category_yes)==0):\n            category_yes = [\"city\",\"country\",\"landmark\"]\n            category_no = []\n            \n        continent_yes = []\n        continent_no = []\n        for k in range(con_guess):\n            if obs.answers[k+cat_guess]==\"yes\":\n                continent_yes.append( continents[k] )\n            else:\n                continent_no.append( continents[k] )\n        if (con_guess==6)&(len(continent_yes)==0):\n            continent_yes = [\"Europe\",\"Asia\",\"North America\",\"Africa\",\"South America\",\"Australia\"]\n            continent_no = []\n            \n        first_letter_yes = []\n        first_letter_no = []\n        for k in range(let_guess):\n            if k >= len(first_letters): continue\n            if obs.answers[k+cat_guess+con_guess]==\"yes\":\n                first_letter_yes.append( first_letters[k] )    \n            else:\n                first_letter_no.append( first_letters[k] ) \n                \n        IDX = keywords.guess == 0\n        if len(category_yes)>0: IDX = IDX & (keywords.category.isin(category_yes))\n        if len(category_no)>0: IDX = IDX & (~keywords.category.isin(category_no))\n        if len(continent_yes)>0: IDX = IDX & (keywords.continent.isin(continent_yes))\n        if len(continent_no)>0: IDX = IDX & (~keywords.continent.isin(continent_no))\n        if len(first_letter_yes)>0: IDX = IDX & (keywords.first_letter.isin(first_letter_yes))\n        if len(first_letter_no)>0: IDX = IDX & (~keywords.first_letter.isin(first_letter_no))\n            \n        try:\n            guess = keywords.loc[IDX].sample(1).index.values[0]\n            keywords.loc[guess,'guess'] = 1\n            response = keywords.loc[guess,\"keyword\"]\n        except:\n            response = np.random.choice( keywords.keyword.values )\n            \n        if (let_guess>0)&(let_guess>=len(first_letters))&(obs.answers[-1]==\"yes\"):\n            response = extra_guess\n        \n    else: #obs.turnType == \"answer\"\n        if obs.keyword.lower() in obs.questions[-1].lower():\n            response = \"yes\"\n        else:\n            response = get_yes_no(obs.questions[-1], obs.keyword)\n            \n    # DISPLAY ROLE\n    if VERBOSE: \n        if obs.turnType == \"answer\": \n            print(f\"Team 2 - Answerer - ### Agent LLAMA 8B ###\")\n        else:\n            print(f\"\\nTeam 2 - Questioner - ### Agent LLAMA 8B ###\")\n        print(f\"OUTPUT = '{response}'\")\n\n    return response","metadata":{},"execution_count":null,"outputs":[]}]}